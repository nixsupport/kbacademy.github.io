{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Understanding Clusters and Nodes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The central component of Amazon EMR is the cluster. A cluster is a collection of Amazon EC2 instances. Each instance in the cluster is called a node. Each node has a role within the cluster, referred to as the node type. \n",
    "\n",
    "Following are the node types supported by EMR.\n",
    "1. Master Node: A node that manages the cluster by running softwarae components which coordinate the distribution of data and atask among other nodes - which are collectively referred to as slave nodes.\n",
    "\n",
    "2. Core/Slave Node: A slave node that has software components which run tasks and store data in the HDFS on your cluster.\n",
    "\n",
    "3. Task node: A slave node that has software components which only run tasks. These nodes are optional."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Submitting Work to a Cluster"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When you run your cluster on Amazon EMR, you have several options as to how you specify the work that needs to be done.\n",
    "\n",
    "1. Provide the entire definition of the work to be done in the Map and Reduce functions. This is typically done fo clusters that process a set amount of data and then terminate when processing is complete.\n",
    "\n",
    "2. Create a long running cluster and use the Amazon EMR console, the Amazon EMR API, or AWWS CLI to submit steps, which may contain one ore more Hadoop jobs.\n",
    "\n",
    "3. Create a cluster with a Hadoop application, such as Hive or Pig, installed and use the interface provided by the application to submit queries, either scripted or interactively. \n",
    "\n",
    "4. Create a long running cluster, connect to it, and submit Hadoop jobs using the Hadoop API."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Processing Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When you launch your cluster, you choose the frameworks and applications to install for your data processing needs. There are two ways to process data in your Amazon EMR cluster: by submitting jobs or queries directly to the applications that are installed on your cluster or by running steps in the cluster."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Submitting Jobs Directly to Applications"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can submit jobs and interact directly with the software that in installed in your Amazon EMR cluster. to do this, you typically connect to the master node over a secure connection and access the interfaces and tools that are available for the software that runs directly on your cluster."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Running Steps to Process Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can submit oen or more ordered steps to an Amazon EMR cluster. Each step is a unit of work that contains instructions to manipulate data for processing by software installed on the cluster.\n",
    "\n",
    "The following is an example process using four steps:\n",
    "\n",
    "1. Submit an input data set for processing\n",
    "2. Process the output of the first step by using a Pig program.\n",
    "3. Process a second input data set by using a Hive program.\n",
    "4. Write an output data set.\n",
    "\n",
    "Steps are run in the following sequence:\n",
    "\n",
    "1. A request is submitted to begin processing steps.\n",
    "2. The state of all steps is set to PENDING.\n",
    "3. When the first step in the sequence starts, its state changes to RUNNING, the other steps remain in the PENDING state.\n",
    "4. After the first step completes, its state changes to COMPLETED.\n",
    "5. The next step in the sequence starts, and its state chages to RUNNING. When it completes, its state changes to COMPLETED.\n",
    "6. This pattern repeats for each step until they all complete and processing ends.\n",
    "\n",
    "If any steps failed, by default, all remaining steps in the sequence are set to CANCELLED. However, you can choose to ignore processing failures and allow remaining steps to proceed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Understanding the Cluster Lifecycle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
